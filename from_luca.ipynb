{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "893018c6-09d0-4004-911e-84a21f912afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(149.8536, dtype=torch.float64)\n",
      "tensor(86.2147, dtype=torch.float64)\n",
      "tensor(51.7964, dtype=torch.float64)\n",
      "tensor(32.4075, dtype=torch.float64)\n",
      "tensor(21.0684, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def convert_csv_to_matrix(input_csv, format):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    df['row'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "    df['col'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "    \n",
    "    max_row = df['row'].max()\n",
    "    max_col = df['col'].max()\n",
    "\n",
    "    if(format == \"zero\"):\n",
    "        matrix = np.zeros((max_row, max_col))\n",
    "        for index, row in df.iterrows():\n",
    "            matrix[row['row']-1, row['col']-1] = row['Prediction']\n",
    "\n",
    "    else:\n",
    "        # Initialize and populate dictionary to store rows\n",
    "        row_dict = {i: {} for i in range(1, max_row + 1)}\n",
    "        for index, row in df.iterrows():\n",
    "            row_dict[row['row']][row['col']] = row['Prediction']\n",
    "\n",
    "\n",
    "        matrix = np.full((max_row, max_col), np.nan)\n",
    "        for r in range(1, max_row + 1):\n",
    "            for c in range(1, max_col + 1):\n",
    "                if c in row_dict[r]:\n",
    "                    matrix[r-1, c-1] = row_dict[r][c]\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def mean_matrix(matrix):\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r])\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    # Normalize the matrix by subtracting the row mean\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r]) - row_mean\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def scale_matrix(matrix):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_matrix = scaler.fit_transform(matrix)\n",
    "    \n",
    "    return scaled_matrix\n",
    "\n",
    "def svd_approximation(matrix):\n",
    "    # SVD Decomposition\n",
    "    U, S, Vh = torch.linalg.svd(matrix, full_matrices=False)\n",
    "\n",
    "    # Set the lowest singular values to zero, e.g. S[-200:] sets the lowest 200 of the total 1000 singular values to zero\n",
    "    S[-200:] = 0\n",
    "    \n",
    "    # Return the matrix calculated by the low rank approximation\n",
    "    return U @ torch.diag(S) @ Vh\n",
    "\n",
    "def save_matrix_to_csv(matrix, relevant_values_csv, output_csv):\n",
    "    # Import the relevant values csv and convert to dataframe\n",
    "    relevant_values_df = pd.DataFrame(convert_csv_to_matrix(relevant_values_csv, 'zero'))\n",
    "    \n",
    "    matrix_df = pd.DataFrame(matrix)\n",
    "    \n",
    "    # Create a filtered version of the matrix. The criteria used is: relevant_values_df == 3\n",
    "    filtered_matrix_df = matrix_df.where(relevant_values_df == 3, other=np.nan)\n",
    "    \n",
    "    # Reshape the matrix into one column and reset the index; also removes NaN values\n",
    "    stacked_df = filtered_matrix_df.stack().reset_index()\n",
    "    \n",
    "    # Rename the columns\n",
    "    stacked_df.columns = ['row', 'col', 'val']\n",
    "    \n",
    "    # Create the desired rN_cN format for the final output\n",
    "    stacked_df['row'] = (stacked_df['row'] + 1).astype(str)\n",
    "    stacked_df['col'] = (stacked_df['col'] + 1).astype(str)\n",
    "    stacked_df['r_c'] = 'r' + stacked_df['row'] + '_c' + stacked_df['col']\n",
    "    \n",
    "    result_df = stacked_df[['r_c', 'val']]\n",
    "    \n",
    "    result_df.to_csv(output_csv, index=False, header=['Id', 'Prediction'])\n",
    "\n",
    "\n",
    "def main(input_csv, relevant_values_csv, output_csv, format):\n",
    "    matrix = convert_csv_to_matrix(input_csv, format)\n",
    "    numpy_matrix = torch.from_numpy(matrix)\n",
    "    known_values_mask = ~torch.isnan(numpy_matrix)\n",
    "    \n",
    "    if format == 'zero':\n",
    "        pass\n",
    "    elif format == 'mean':\n",
    "        matrix = mean_matrix(matrix)\n",
    "    elif format == 'normalize':\n",
    "        # Normalize the matrix\n",
    "        matrix = normalize_matrix(matrix)\n",
    "    elif format == 'scale':\n",
    "        # Normalize and scale the matrix\n",
    "        matrix = normalize_matrix(matrix)\n",
    "        matrix = scale_matrix(matrix)\n",
    "    elif format == 'svd':\n",
    "        # Use SVD for low rank approximation\n",
    "        \n",
    "        # Mean imputated matrix\n",
    "        svd_matrix = torch.from_numpy(mean_matrix(matrix))\n",
    "        \n",
    "        # Iterate through SVD approximating and re-filling the known original values\n",
    "        for _ in range(5):\n",
    "            svd_matrix = svd_approximation(svd_matrix)\n",
    "            # Metric on how close the approximated values match the known values\n",
    "            print(torch.dist(svd_matrix[known_values_mask], numpy_matrix[known_values_mask]))\n",
    "            \n",
    "            # Re-fill the known original values\n",
    "            svd_matrix[known_values_mask] = numpy_matrix[known_values_mask]\n",
    "        \n",
    "    else:\n",
    "        print(f\"Unknown action: {format}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Save the matrix to the output CSV\n",
    "    save_matrix_to_csv(svd_matrix, relevant_values_csv, output_csv)\n",
    "\n",
    "main('data_train.csv', 'sampleSubmission.csv', 'result.csv', \"svd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabac65-64f4-46b0-a808-f4b4996109b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

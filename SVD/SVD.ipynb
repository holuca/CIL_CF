{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "9c5be54d7289ab0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:24:06.709340Z",
     "start_time": "2024-07-29T17:24:06.707198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ],
   "id": "55a4fbc7e168f289",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supporting Functions",
   "id": "c539a403a41bcae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:24:06.725447Z",
     "start_time": "2024-07-29T17:24:06.723501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definition of file names to import and export\n",
    "input_csv, relevant_values_csv, output_csv = 'data_train.csv', 'sampleSubmission.csv', 'result.csv'"
   ],
   "id": "8842ceff36eb817d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:24:06.747551Z",
     "start_time": "2024-07-29T17:24:06.742833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_csv_to_matrix(input_csv, format):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    df['row'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "    df['col'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "    \n",
    "    max_row = df['row'].max()\n",
    "    max_col = df['col'].max()\n",
    "\n",
    "    if(format == \"zero\"):\n",
    "        matrix = np.zeros((max_row, max_col))\n",
    "        for index, row in df.iterrows():\n",
    "            matrix[row['row']-1, row['col']-1] = row['Prediction']\n",
    "\n",
    "    else:\n",
    "        # Initialize and populate dictionary to store rows\n",
    "        row_dict = {i: {} for i in range(1, max_row + 1)}\n",
    "        for index, row in df.iterrows():\n",
    "            row_dict[row['row']][row['col']] = row['Prediction']\n",
    "\n",
    "\n",
    "        matrix = np.full((max_row, max_col), np.nan)\n",
    "        for r in range(1, max_row + 1):\n",
    "            for c in range(1, max_col + 1):\n",
    "                if c in row_dict[r]:\n",
    "                    matrix[r-1, c-1] = row_dict[r][c]\n",
    "    \n",
    "    return matrix"
   ],
   "id": "ecd181b130820d28",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:24:06.752114Z",
     "start_time": "2024-07-29T17:24:06.748984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_matrix_to_csv(matrix, relevant_values_csv, output_csv):\n",
    "    # Import the relevant values csv and convert to dataframe\n",
    "    relevant_values_df = pd.DataFrame(convert_csv_to_matrix(relevant_values_csv, 'zero'))\n",
    "    \n",
    "    matrix_df = pd.DataFrame(matrix)\n",
    "    \n",
    "    # Create a filtered version of the matrix. The criteria used is: relevant_values_df == 3\n",
    "    filtered_matrix_df = matrix_df.where(relevant_values_df == 3, other=np.nan)\n",
    "    \n",
    "    # Reshape the matrix into one column and reset the index; also removes NaN values\n",
    "    stacked_df = filtered_matrix_df.stack().reset_index()\n",
    "    \n",
    "    # Rename the columns\n",
    "    stacked_df.columns = ['row', 'col', 'val']\n",
    "    \n",
    "    # Create the desired rN_cN format for the final output\n",
    "    stacked_df['row'] = (stacked_df['row'] + 1).astype(str)\n",
    "    stacked_df['col'] = (stacked_df['col'] + 1).astype(str)\n",
    "    stacked_df['r_c'] = 'r' + stacked_df['row'] + '_c' + stacked_df['col']\n",
    "    \n",
    "    result_df = stacked_df[['r_c', 'val']]\n",
    "    \n",
    "    result_df.to_csv(output_csv, index=False, header=['Id', 'Prediction'])"
   ],
   "id": "601e565ac349fe2a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:24:06.755315Z",
     "start_time": "2024-07-29T17:24:06.753197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# impute missing entries og the matrix with the row mean\n",
    "def mean_matrix(matrix):\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r])\n",
    "    return matrix\n"
   ],
   "id": "c43a102b91f428f9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Choose Parameters",
   "id": "79d12f7ae6599b83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:27:50.220677Z",
     "start_time": "2024-07-29T17:27:50.218491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mode = \"singular_values_shrink\"  # All options: \"singular_values_fixed\", \"singular_values_shrink\",\"singular_value_thresholding\"\n",
    "num_iterations = 26\n",
    "eta = 1\n",
    "center_data = False             # Whether to center the data before SVD; only applicable for modes singular_values_fixed and singular_values_shrink \n",
    "shrinkage_tau = 42             # Used in the modes singular_values_shrink and singular_value_thresholding\n",
    "num_keep_singular_values = 8    # Used in the mode singular_values_fixed\n",
    "activate_validation = False    # Use test/validation sets for loss"
   ],
   "id": "a338bcc45db44164",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Iterative SVD Algorithms\n",
    "\n",
    "Adapted from the lecture script and exercise materials"
   ],
   "id": "f1d99de7683749bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:27:51.010766Z",
     "start_time": "2024-07-29T17:27:51.008647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Returns the singular values matrix S with all values smaller than tau being set to 0\n",
    "def shrink(S):\n",
    "    S[:] -= shrinkage_tau\n",
    "    return torch.clamp(S, min=0)"
   ],
   "id": "a4659be8ced21697",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:27:51.380493Z",
     "start_time": "2024-07-29T17:27:51.377763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Returns an SVD approximation of a given matrix, controlled by the parameters shrinkage_tau, num_keep_singular_values and mode\n",
    "def svd_approximation(matrix):\n",
    "    \n",
    "    # SVD Decomposition\n",
    "    U, S, Vh = torch.linalg.svd(matrix, full_matrices=False)\n",
    "    \n",
    "    if mode == \"singular_values_fixed\":\n",
    "    # Only keep the largest num_keep_singular_values singular values, all others are set to zero\n",
    "        S[-1*(min(list(matrix.shape)) - num_keep_singular_values):] = 0\n",
    "    \n",
    "    elif mode == \"singular_values_shrink\" or mode == \"singular_value_thresholding\":\n",
    "    # Nuclear Norm\n",
    "        S = shrink(S)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    # Return the matrix calculated by the low rank approximation\n",
    "    return U @ torch.diag(S) @ Vh"
   ],
   "id": "9b6604d34be8da72",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:28:12.593811Z",
     "start_time": "2024-07-29T17:27:51.645812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import matrix from CSV, impute missing values by the row means, and convert into a torch tensor\n",
    "matrix = convert_csv_to_matrix(input_csv, \"svd\")\n",
    "torch_matrix = torch.from_numpy(matrix)\n",
    "\n",
    "# Create mask of the known values\n",
    "known_values_mask = ~torch.isnan(torch_matrix)\n",
    "\n",
    "testing_values_mask = known_values_mask.clone()\n",
    "\n",
    "validation_size_relative = 0.1               # size of validation set relative to total size\n",
    "validation_size = round(validation_size_relative * testing_values_mask.shape[1])\n",
    "train_size = round((1 - validation_size_relative) * testing_values_mask.shape[1])\n",
    "total_size = train_size + validation_size\n",
    "if activate_validation:\n",
    "    # Define validation and training sets\n",
    "    testing_values_mask[:,:train_size] = False # validation data mask: The last validation_size percent of the users\n",
    "    known_values_mask[:,train_size:] = False # training data mask: The other users coming before"
   ],
   "id": "44545a09fb4a6e7c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:28:56.240514Z",
     "start_time": "2024-07-29T17:28:12.595014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Impute the missing values of the matrix by the row mean\n",
    "svd_matrix = torch.from_numpy(mean_matrix(matrix))\n",
    "\n",
    "# Iterate through SVD approximating and re-filling the known original values\n",
    "for iteration in range(num_iterations):\n",
    "    if mode == \"singular_values_fixed\" or mode == \"singular_values_shrink\":\n",
    "        # Re-fill the known original values with variable eta\n",
    "        svd_matrix[known_values_mask] = svd_matrix[known_values_mask] + eta * (torch_matrix[known_values_mask] - svd_matrix[known_values_mask])\n",
    "        \n",
    "        if center_data:\n",
    "            # Subtract mean from matrix\n",
    "            matrix_mean = svd_matrix.mean(dim=1, keepdim=True)\n",
    "            svd_matrix_centered = svd_matrix - matrix_mean\n",
    "            \n",
    "            # Calculate SVD approximation, shift by previously subtracted mean and clamp values to [1,5]\n",
    "            svd_matrix = torch.clamp(svd_approximation(svd_matrix_centered) + matrix_mean, min=1.0, max=5.0)\n",
    "        else:\n",
    "            # Calculate SVD approximation and clamp values to [1,5]\n",
    "            svd_matrix = torch.clamp(svd_approximation(svd_matrix), min=1.0, max=5.0)\n",
    "        \n",
    "        # Metric on how close the approximated values match the known values\n",
    "        if activate_validation:\n",
    "            print(f'ITERATION: {iteration:03}, Validation Error: {round(math.sqrt(torch.nn.functional.mse_loss(svd_matrix[testing_values_mask], torch_matrix[testing_values_mask]).item()),5)}, Training Error: {round(math.sqrt(torch.nn.functional.mse_loss(svd_matrix[known_values_mask], torch_matrix[known_values_mask]).item()),5)}')\n",
    "        else:\n",
    "            print(f'ITERATION: {iteration:03}, Error: {round(math.sqrt(torch.nn.functional.mse_loss(svd_matrix[testing_values_mask], torch_matrix[testing_values_mask]).item()),5)}')\n",
    "       \n",
    "    \n",
    "    elif mode == \"singular_value_thresholding\":\n",
    "        # Follow procedure as described in formula (2.41), mean imputed matrix used as A0\n",
    "        matrix_shrink = svd_approximation(svd_matrix)\n",
    "        svd_matrix[known_values_mask] = svd_matrix[known_values_mask] + eta * (torch_matrix[known_values_mask] - matrix_shrink[known_values_mask])\n",
    "        \n",
    "        # Metric on how close the approximated values match the known values\n",
    "        if activate_validation:\n",
    "            print(f'ITERATION: {iteration:03}, Validation Error: {round(math.sqrt(torch.nn.functional.mse_loss(svd_approximation(svd_matrix)[testing_values_mask], torch_matrix[testing_values_mask]).item()),5)}, Training Error: {round(math.sqrt(torch.nn.functional.mse_loss(svd_approximation(svd_matrix)[known_values_mask], torch_matrix[known_values_mask]).item()),5)}')\n",
    "        else:    \n",
    "            print(f'ITERATION: {iteration:03}, Error: {round(math.sqrt(torch.nn.functional.mse_loss(svd_approximation(svd_matrix)[testing_values_mask]/total_size, torch_matrix[testing_values_mask]).item()),5)}')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "# Output matrix\n",
    "if mode == \"singular_values_fixed\" or mode == \"singular_values_shrink\":\n",
    "    matrix_out = svd_matrix\n",
    "elif mode == \"singular_value_thresholding\":\n",
    "    matrix_out = torch.clamp(svd_approximation(svd_matrix), min=1.0, max=5.0)\n",
    "else:\n",
    "    raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "# Save the matrix to the output CSV\n",
    "save_matrix_to_csv(matrix_out, relevant_values_csv, output_csv)"
   ],
   "id": "893018c6-09d0-4004-911e-84a21f912afd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 000, Error: 0.91662\n",
      "ITERATION: 001, Error: 0.89704\n",
      "ITERATION: 002, Error: 0.8858\n",
      "ITERATION: 003, Error: 0.87906\n",
      "ITERATION: 004, Error: 0.87454\n",
      "ITERATION: 005, Error: 0.87137\n",
      "ITERATION: 006, Error: 0.86903\n",
      "ITERATION: 007, Error: 0.86725\n",
      "ITERATION: 008, Error: 0.86584\n",
      "ITERATION: 009, Error: 0.8647\n",
      "ITERATION: 010, Error: 0.86377\n",
      "ITERATION: 011, Error: 0.863\n",
      "ITERATION: 012, Error: 0.86235\n",
      "ITERATION: 013, Error: 0.86181\n",
      "ITERATION: 014, Error: 0.86136\n",
      "ITERATION: 015, Error: 0.86098\n",
      "ITERATION: 016, Error: 0.86066\n",
      "ITERATION: 017, Error: 0.8604\n",
      "ITERATION: 018, Error: 0.86018\n",
      "ITERATION: 019, Error: 0.86\n",
      "ITERATION: 020, Error: 0.85987\n",
      "ITERATION: 021, Error: 0.85976\n",
      "ITERATION: 022, Error: 0.85969\n",
      "ITERATION: 023, Error: 0.85963\n",
      "ITERATION: 024, Error: 0.85961\n",
      "ITERATION: 025, Error: 0.8596\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:25:13.215677Z",
     "start_time": "2024-07-29T17:25:13.214411Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58e289f71b33bd88",
   "outputs": [],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "9c5be54d7289ab0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:26:46.107427Z",
     "start_time": "2024-07-29T15:26:45.023593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ],
   "id": "55a4fbc7e168f289",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supporting Functions",
   "id": "c539a403a41bcae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:26:50.717641Z",
     "start_time": "2024-07-29T15:26:50.715519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definition of file names to import and export\n",
    "input_csv, relevant_values_csv, output_csv = 'data_train.csv', 'sampleSubmission.csv', 'result.csv'"
   ],
   "id": "8842ceff36eb817d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:26:52.119200Z",
     "start_time": "2024-07-29T15:26:52.113947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_csv_to_matrix(input_csv, format):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    df['row'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "    df['col'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "    \n",
    "    max_row = df['row'].max()\n",
    "    max_col = df['col'].max()\n",
    "\n",
    "    if(format == \"zero\"):\n",
    "        matrix = np.zeros((max_row, max_col))\n",
    "        for index, row in df.iterrows():\n",
    "            matrix[row['row']-1, row['col']-1] = row['Prediction']\n",
    "\n",
    "    else:\n",
    "        # Initialize and populate dictionary to store rows\n",
    "        row_dict = {i: {} for i in range(1, max_row + 1)}\n",
    "        for index, row in df.iterrows():\n",
    "            row_dict[row['row']][row['col']] = row['Prediction']\n",
    "\n",
    "\n",
    "        matrix = np.full((max_row, max_col), np.nan)\n",
    "        for r in range(1, max_row + 1):\n",
    "            for c in range(1, max_col + 1):\n",
    "                if c in row_dict[r]:\n",
    "                    matrix[r-1, c-1] = row_dict[r][c]\n",
    "    \n",
    "    return matrix"
   ],
   "id": "ecd181b130820d28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:26:52.873434Z",
     "start_time": "2024-07-29T15:26:52.869130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_matrix_to_csv(matrix, relevant_values_csv, output_csv):\n",
    "    # Import the relevant values csv and convert to dataframe\n",
    "    relevant_values_df = pd.DataFrame(convert_csv_to_matrix(relevant_values_csv, 'zero'))\n",
    "    \n",
    "    matrix_df = pd.DataFrame(matrix)\n",
    "    \n",
    "    # Create a filtered version of the matrix. The criteria used is: relevant_values_df == 3\n",
    "    filtered_matrix_df = matrix_df.where(relevant_values_df == 3, other=np.nan)\n",
    "    \n",
    "    # Reshape the matrix into one column and reset the index; also removes NaN values\n",
    "    stacked_df = filtered_matrix_df.stack().reset_index()\n",
    "    \n",
    "    # Rename the columns\n",
    "    stacked_df.columns = ['row', 'col', 'val']\n",
    "    \n",
    "    # Create the desired rN_cN format for the final output\n",
    "    stacked_df['row'] = (stacked_df['row'] + 1).astype(str)\n",
    "    stacked_df['col'] = (stacked_df['col'] + 1).astype(str)\n",
    "    stacked_df['r_c'] = 'r' + stacked_df['row'] + '_c' + stacked_df['col']\n",
    "    \n",
    "    result_df = stacked_df[['r_c', 'val']]\n",
    "    \n",
    "    result_df.to_csv(output_csv, index=False, header=['Id', 'Prediction'])"
   ],
   "id": "601e565ac349fe2a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:26:54.425453Z",
     "start_time": "2024-07-29T15:26:54.422900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# impute missing entries og the matrix with the row mean\n",
    "def mean_matrix(matrix):\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r])\n",
    "    return matrix\n"
   ],
   "id": "c43a102b91f428f9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Choose Parameters",
   "id": "79d12f7ae6599b83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:27.677182Z",
     "start_time": "2024-07-29T16:32:27.674888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mode = \"singular_value_thresholding\"  # All options: \"singular_values_fixed\", \"singular_values_shrink\",\"singular_value_thresholding\"\n",
    "num_iterations = 20\n",
    "eta = 1\n",
    "center_data = False             # Whether to center the data before SVD; only applicable for modes singular_values_fixed and singular_values_shrink \n",
    "shrinkage_tau = 42             # Used in the modes singular_values_shrink and singular_value_thresholding\n",
    "num_keep_singular_values = 8    # Used in the mode singular_values_fixed\n",
    "activate_validation = True    # Use test/validation sets for loss"
   ],
   "id": "a338bcc45db44164",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Iterative SVD Algorithms\n",
    "\n",
    "Adapted from the lecture script and exercise materials"
   ],
   "id": "f1d99de7683749bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:28.472733Z",
     "start_time": "2024-07-29T16:32:28.470224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Returns the singular values matrix S with all values smaller than tau being set to 0\n",
    "def shrink(S):\n",
    "    S[:] -= shrinkage_tau\n",
    "    return torch.clamp(S, min=0)"
   ],
   "id": "a4659be8ced21697",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:28.835236Z",
     "start_time": "2024-07-29T16:32:28.832365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Returns an SVD approximation of a given matrix, controlled by the parameters shrinkage_tau, num_keep_singular_values and mode\n",
    "def svd_approximation(matrix):\n",
    "    \n",
    "    # SVD Decomposition\n",
    "    U, S, Vh = torch.linalg.svd(matrix, full_matrices=False)\n",
    "    \n",
    "    if mode == \"singular_values_fixed\":\n",
    "    # Only keep the largest num_keep_singular_values singular values, all others are set to zero\n",
    "        S[-1*(min(list(matrix.shape)) - num_keep_singular_values):] = 0\n",
    "    \n",
    "    elif mode == \"singular_values_shrink\" or mode == \"singular_value_thresholding\":\n",
    "    # Nuclear Norm\n",
    "        S = shrink(S)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    # Return the matrix calculated by the low rank approximation\n",
    "    return U @ torch.diag(S) @ Vh"
   ],
   "id": "9b6604d34be8da72",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:51.720920Z",
     "start_time": "2024-07-29T16:32:29.253123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import matrix from CSV, impute missing values by the row means, and convert into a torch tensor\n",
    "matrix = convert_csv_to_matrix(input_csv, \"svd\")\n",
    "torch_matrix = torch.from_numpy(matrix)\n",
    "\n",
    "# Create mask of the known values\n",
    "known_values_mask = ~torch.isnan(torch_matrix)\n",
    "\n",
    "testing_values_mask = known_values_mask.clone()\n",
    "\n",
    "validation_size_relative = 0.1               # size of validation set relative to total size\n",
    "validation_size = round(validation_size_relative * testing_values_mask.shape[1])\n",
    "train_size = round((1 - validation_size_relative) * testing_values_mask.shape[1])\n",
    "total_size = train_size + validation_size\n",
    "if activate_validation:\n",
    "    # Define validation and training sets\n",
    "    testing_values_mask[:,:train_size] = False # validation data mask: The last validation_size percent of the users\n",
    "    known_values_mask[:,train_size:] = False # training data mask: The other users coming before"
   ],
   "id": "44545a09fb4a6e7c",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:34:04.699545Z",
     "start_time": "2024-07-29T16:32:51.722340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Impute the missing values of the matrix by the row mean\n",
    "svd_matrix = torch.from_numpy(mean_matrix(matrix))\n",
    "\n",
    "# Iterate through SVD approximating and re-filling the known original values\n",
    "for iteration in range(num_iterations):\n",
    "    if mode == \"singular_values_fixed\" or mode == \"singular_values_shrink\":\n",
    "        # Re-fill the known original values with variable eta\n",
    "        svd_matrix[known_values_mask] = svd_matrix[known_values_mask] + eta * (torch_matrix[known_values_mask] - svd_matrix[known_values_mask])\n",
    "        \n",
    "        if center_data:\n",
    "            # Subtract mean from matrix\n",
    "            matrix_mean = svd_matrix.mean(dim=1, keepdim=True)\n",
    "            svd_matrix_centered = svd_matrix - matrix_mean\n",
    "            \n",
    "            # Calculate SVD approximation, shift by previously subtracted mean and clamp values to [1,5]\n",
    "            svd_matrix = torch.clamp(svd_approximation(svd_matrix_centered) + matrix_mean, min=1.0, max=5.0)\n",
    "        else:\n",
    "            # Calculate SVD approximation and clamp values to [1,5]\n",
    "            svd_matrix = torch.clamp(svd_approximation(svd_matrix), min=1.0, max=5.0)\n",
    "        \n",
    "        # Metric on how close the approximated values match the known values\n",
    "        if activate_validation:\n",
    "            print(f'ITERATION: {iteration:03}, Validation Loss: {round(torch.dist(svd_matrix[testing_values_mask], torch_matrix[testing_values_mask]).item()/validation_size,5)}, Training Loss: {round(torch.dist(svd_matrix[known_values_mask], torch_matrix[known_values_mask]).item()/train_size,5)}')\n",
    "        else:\n",
    "            print(f'ITERATION: {iteration:03}, Loss: {round(torch.dist(svd_matrix[testing_values_mask], torch_matrix[testing_values_mask]).item()/total_size,5)}')\n",
    "       \n",
    "    \n",
    "    elif mode == \"singular_value_thresholding\":\n",
    "        # Follow procedure as described in formula (2.41), mean imputed matrix used as A0\n",
    "        matrix_shrink = svd_approximation(svd_matrix)\n",
    "        svd_matrix[known_values_mask] = svd_matrix[known_values_mask] + eta * (torch_matrix[known_values_mask] - matrix_shrink[known_values_mask])\n",
    "        \n",
    "        # Metric on how close the approximated values match the known values\n",
    "        if activate_validation:\n",
    "            print(f'ITERATION: {iteration:03}, Validation Loss: {round(torch.dist(svd_approximation(svd_matrix)[testing_values_mask], torch_matrix[testing_values_mask]).item()/validation_size,5)}, Training Loss: {round(torch.dist(svd_approximation(svd_matrix)[known_values_mask], torch_matrix[known_values_mask]).item()/train_size,5)}')\n",
    "        else:    \n",
    "            print(f'ITERATION: {iteration:03}, Loss: {round(torch.dist(svd_approximation(svd_matrix)[testing_values_mask]/total_size, torch_matrix[testing_values_mask]).item()/total_size,5)}')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "# Output matrix\n",
    "if mode == \"singular_values_fixed\" or mode == \"singular_values_shrink\":\n",
    "    matrix_out = svd_matrix\n",
    "elif mode == \"singular_value_thresholding\":\n",
    "    matrix_out = torch.clamp(svd_approximation(svd_matrix), min=1.0, max=5.0)\n",
    "else:\n",
    "    raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "# Save the matrix to the output CSV\n",
    "save_matrix_to_csv(matrix_out, relevant_values_csv, output_csv)"
   ],
   "id": "893018c6-09d0-4004-911e-84a21f912afd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 000, Validation Loss: 2.67522, Training Loss: 1.30366\n",
      "ITERATION: 001, Validation Loss: 2.62749, Training Loss: 1.36008\n",
      "ITERATION: 002, Validation Loss: 2.60589, Training Loss: 1.37094\n",
      "ITERATION: 003, Validation Loss: 2.5955, Training Loss: 1.37358\n",
      "ITERATION: 004, Validation Loss: 2.58896, Training Loss: 1.37535\n",
      "ITERATION: 005, Validation Loss: 2.58422, Training Loss: 1.37669\n",
      "ITERATION: 006, Validation Loss: 2.58057, Training Loss: 1.37775\n",
      "ITERATION: 007, Validation Loss: 2.57766, Training Loss: 1.37862\n",
      "ITERATION: 008, Validation Loss: 2.57529, Training Loss: 1.37935\n",
      "ITERATION: 009, Validation Loss: 2.5733, Training Loss: 1.37999\n",
      "ITERATION: 010, Validation Loss: 2.57161, Training Loss: 1.38054\n",
      "ITERATION: 011, Validation Loss: 2.57016, Training Loss: 1.38103\n",
      "ITERATION: 012, Validation Loss: 2.5689, Training Loss: 1.38147\n",
      "ITERATION: 013, Validation Loss: 2.56779, Training Loss: 1.38186\n",
      "ITERATION: 014, Validation Loss: 2.56681, Training Loss: 1.38222\n",
      "ITERATION: 015, Validation Loss: 2.56594, Training Loss: 1.38255\n",
      "ITERATION: 016, Validation Loss: 2.56516, Training Loss: 1.38285\n",
      "ITERATION: 017, Validation Loss: 2.56446, Training Loss: 1.38313\n",
      "ITERATION: 018, Validation Loss: 2.56383, Training Loss: 1.38339\n",
      "ITERATION: 019, Validation Loss: 2.56324, Training Loss: 1.38363\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:08:24.114049Z",
     "start_time": "2024-07-27T14:08:24.112573Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58e289f71b33bd88",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "9c5be54d7289ab0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.524843Z",
     "start_time": "2024-07-27T14:07:16.563437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ],
   "id": "55a4fbc7e168f289",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supporting Functions",
   "id": "c539a403a41bcae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.527765Z",
     "start_time": "2024-07-27T14:07:17.525909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definition of file names to import and export\n",
    "input_csv, relevant_values_csv, output_csv = 'data_train.csv', 'sampleSubmission.csv', 'result.csv'"
   ],
   "id": "8842ceff36eb817d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.532439Z",
     "start_time": "2024-07-27T14:07:17.528404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_csv_to_matrix(input_csv, format):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    df['row'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "    df['col'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "    \n",
    "    max_row = df['row'].max()\n",
    "    max_col = df['col'].max()\n",
    "\n",
    "    if(format == \"zero\"):\n",
    "        matrix = np.zeros((max_row, max_col))\n",
    "        for index, row in df.iterrows():\n",
    "            matrix[row['row']-1, row['col']-1] = row['Prediction']\n",
    "\n",
    "    else:\n",
    "        # Initialize and populate dictionary to store rows\n",
    "        row_dict = {i: {} for i in range(1, max_row + 1)}\n",
    "        for index, row in df.iterrows():\n",
    "            row_dict[row['row']][row['col']] = row['Prediction']\n",
    "\n",
    "\n",
    "        matrix = np.full((max_row, max_col), np.nan)\n",
    "        for r in range(1, max_row + 1):\n",
    "            for c in range(1, max_col + 1):\n",
    "                if c in row_dict[r]:\n",
    "                    matrix[r-1, c-1] = row_dict[r][c]\n",
    "    \n",
    "    return matrix"
   ],
   "id": "ecd181b130820d28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.536540Z",
     "start_time": "2024-07-27T14:07:17.533953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_matrix_to_csv(matrix, relevant_values_csv, output_csv):\n",
    "    # Import the relevant values csv and convert to dataframe\n",
    "    relevant_values_df = pd.DataFrame(convert_csv_to_matrix(relevant_values_csv, 'zero'))\n",
    "    \n",
    "    matrix_df = pd.DataFrame(matrix)\n",
    "    \n",
    "    # Create a filtered version of the matrix. The criteria used is: relevant_values_df == 3\n",
    "    filtered_matrix_df = matrix_df.where(relevant_values_df == 3, other=np.nan)\n",
    "    \n",
    "    # Reshape the matrix into one column and reset the index; also removes NaN values\n",
    "    stacked_df = filtered_matrix_df.stack().reset_index()\n",
    "    \n",
    "    # Rename the columns\n",
    "    stacked_df.columns = ['row', 'col', 'val']\n",
    "    \n",
    "    # Create the desired rN_cN format for the final output\n",
    "    stacked_df['row'] = (stacked_df['row'] + 1).astype(str)\n",
    "    stacked_df['col'] = (stacked_df['col'] + 1).astype(str)\n",
    "    stacked_df['r_c'] = 'r' + stacked_df['row'] + '_c' + stacked_df['col']\n",
    "    \n",
    "    result_df = stacked_df[['r_c', 'val']]\n",
    "    \n",
    "    result_df.to_csv(output_csv, index=False, header=['Id', 'Prediction'])"
   ],
   "id": "601e565ac349fe2a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.539128Z",
     "start_time": "2024-07-27T14:07:17.537252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# impute missing entries og the matrix with the row mean\n",
    "def mean_matrix(matrix):\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r])\n",
    "    return matrix\n"
   ],
   "id": "c43a102b91f428f9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Choose Parameters",
   "id": "79d12f7ae6599b83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.541480Z",
     "start_time": "2024-07-27T14:07:17.539624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mode = \"singular_values_shrink\"  # All options: \"singular_values_fixed\", \"singular_values_shrink\",\"singular_value_thresholding\"\n",
    "num_iterations = 26\n",
    "eta = 1\n",
    "center_data = False             # Whether to center the data before SVD; only applicable for modes singular_values_fixed and singular_values_shrink \n",
    "shrinkage_tau = 42             # Used in the modes singular_values_shrink and singular_value_thresholding\n",
    "num_keep_singular_values = 8    # Used in the mode singular_values_fixed\n",
    "activate_validation = False     # Use test/validation sets for loss"
   ],
   "id": "a338bcc45db44164",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Iterative SVD Algorithms\n",
    "\n",
    "Adapted from the lecture script and exercise materials"
   ],
   "id": "f1d99de7683749bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.543799Z",
     "start_time": "2024-07-27T14:07:17.541982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Returns the singular values matrix S with all values smaller than tau being set to 0\n",
    "def shrink(S):\n",
    "    S[:] -= shrinkage_tau\n",
    "    return torch.clamp(S, min=0)"
   ],
   "id": "a4659be8ced21697",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:17.546664Z",
     "start_time": "2024-07-27T14:07:17.544445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Returns an SVD approximation of a given matrix, controlled by the parameters shrinkage_tau, num_keep_singular_values and mode\n",
    "def svd_approximation(matrix):\n",
    "    \n",
    "    # SVD Decomposition\n",
    "    U, S, Vh = torch.linalg.svd(matrix, full_matrices=False)\n",
    "    \n",
    "    if mode == \"singular_values_fixed\":\n",
    "    # Only keep the largest num_keep_singular_values singular values, all others are set to zero\n",
    "        S[-1*(min(list(matrix.shape)) - num_keep_singular_values):] = 0\n",
    "    \n",
    "    elif mode == \"singular_values_shrink\" or mode == \"singular_value_thresholding\":\n",
    "    # Nuclear Norm\n",
    "        S = shrink(S)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    # Return the matrix calculated by the low rank approximation\n",
    "    return U @ torch.diag(S) @ Vh"
   ],
   "id": "9b6604d34be8da72",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:07:39.541126Z",
     "start_time": "2024-07-27T14:07:17.547448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import matrix from CSV, impute missing values by the row means, and convert into a torch tensor\n",
    "matrix = convert_csv_to_matrix(input_csv, \"svd\")\n",
    "torch_matrix = torch.from_numpy(matrix)\n",
    "\n",
    "# Create mask of the known values\n",
    "known_values_mask = ~torch.isnan(torch_matrix)\n",
    "\n",
    "testing_values_mask = known_values_mask.clone()\n",
    "if activate_validation:\n",
    "    # Define validation and training sets\n",
    "    testing_values_mask[:,:990] = False # validation data mask: The last 10 users\n",
    "    known_values_mask[:,990:] = False # training data mask: The first 990 users"
   ],
   "id": "44545a09fb4a6e7c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:08:24.111915Z",
     "start_time": "2024-07-27T14:07:39.544630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Impute the missing values of the matrix by the row mean\n",
    "svd_matrix = torch.from_numpy(mean_matrix(matrix))\n",
    "\n",
    "# Iterate through SVD approximating and re-filling the known original values\n",
    "for iteration in range(num_iterations):\n",
    "    if mode == \"singular_values_fixed\" or mode == \"singular_values_shrink\":\n",
    "        # Re-fill the known original values with variable eta\n",
    "        svd_matrix[known_values_mask] = svd_matrix[known_values_mask] + eta * (torch_matrix[known_values_mask] - svd_matrix[known_values_mask])\n",
    "        \n",
    "        if center_data:\n",
    "            # Subtract mean from matrix\n",
    "            matrix_mean = svd_matrix.mean(dim=1, keepdim=True)\n",
    "            svd_matrix_centered = svd_matrix - matrix_mean\n",
    "            \n",
    "            # Calculate SVD approximation, shift by previously subtracted mean and clamp values to [1,5]\n",
    "            svd_matrix = torch.clamp(svd_approximation(svd_matrix_centered) + matrix_mean, min=1.0, max=5.0)\n",
    "        else:\n",
    "            # Calculate SVD approximation and clamp values to [1,5]\n",
    "            svd_matrix = torch.clamp(svd_approximation(svd_matrix), min=1.0, max=5.0)\n",
    "        \n",
    "        # Metric on how close the approximated values match the known values\n",
    "        print(f'ITERATION: {iteration:03}, Error: {torch.dist(svd_matrix[testing_values_mask], torch_matrix[testing_values_mask]).item()}')\n",
    "    \n",
    "    elif mode == \"singular_value_thresholding\":\n",
    "        # Follow procedure as described in formula (2.41), mean imputed matrix used as A0\n",
    "        matrix_shrink = svd_approximation(svd_matrix)\n",
    "        svd_matrix[known_values_mask] = svd_matrix[known_values_mask] + eta * (torch_matrix[known_values_mask] - matrix_shrink[known_values_mask])\n",
    "        \n",
    "        # Metric on how close the approximated values match the known values\n",
    "        print(f'ITERATION: {iteration:03}, Error: {torch.dist(svd_approximation(svd_matrix)[testing_values_mask], torch_matrix[testing_values_mask]).item()}')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "    # Metric on how close the approximated values match the known values\n",
    "    # print(f'ITERATION: {iteration:03}, Error: {torch.dist(svd_matrix[testing_values_mask], torch_matrix[testing_values_mask]).item()}')\n",
    "    \n",
    "# Output matrix\n",
    "if mode == \"singular_values_fixed\" or mode == \"singular_values_shrink\":\n",
    "    matrix_out = svd_matrix\n",
    "elif mode == \"singular_value_thresholding\":\n",
    "    matrix_out = torch.clamp(svd_approximation(svd_matrix), min=1.0, max=5.0)\n",
    "else:\n",
    "    raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "# Save the matrix to the output CSV\n",
    "save_matrix_to_csv(matrix_out, relevant_values_csv, output_csv)"
   ],
   "id": "893018c6-09d0-4004-911e-84a21f912afd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 000, Error: 994.4163409085834\n",
      "ITERATION: 001, Error: 973.1796458012631\n",
      "ITERATION: 002, Error: 960.983958826122\n",
      "ITERATION: 003, Error: 953.6664712860837\n",
      "ITERATION: 004, Error: 948.7676574620516\n",
      "ITERATION: 005, Error: 945.3308491096333\n",
      "ITERATION: 006, Error: 942.7925509378496\n",
      "ITERATION: 007, Error: 940.8577386781617\n",
      "ITERATION: 008, Error: 939.3283453153902\n",
      "ITERATION: 009, Error: 938.0929160336664\n",
      "ITERATION: 010, Error: 937.0813393522102\n",
      "ITERATION: 011, Error: 936.2413846476635\n",
      "ITERATION: 012, Error: 935.5394364311394\n",
      "ITERATION: 013, Error: 934.9538899270341\n",
      "ITERATION: 014, Error: 934.4658766704243\n",
      "ITERATION: 015, Error: 934.0541488779024\n",
      "ITERATION: 016, Error: 933.7077224640101\n",
      "ITERATION: 017, Error: 933.422502591554\n",
      "ITERATION: 018, Error: 933.1865341820964\n",
      "ITERATION: 019, Error: 932.9970229424135\n",
      "ITERATION: 020, Error: 932.8477594900166\n",
      "ITERATION: 021, Error: 932.7338237062623\n",
      "ITERATION: 022, Error: 932.6504055212816\n",
      "ITERATION: 023, Error: 932.5944930371405\n",
      "ITERATION: 024, Error: 932.5636010556507\n",
      "ITERATION: 025, Error: 932.5548589396464\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:08:24.114049Z",
     "start_time": "2024-07-27T14:08:24.112573Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58e289f71b33bd88",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

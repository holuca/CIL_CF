{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:55:58.107497Z",
     "start_time": "2024-07-15T16:55:51.750950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ],
   "id": "3d7c812ad2026d44",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:00.208348Z",
     "start_time": "2024-07-15T16:56:00.206423Z"
    }
   },
   "cell_type": "code",
   "source": "input_csv, relevant_values_csv, output_csv = 'data_train.csv', 'sampleSubmission.csv', 'result.csv'",
   "id": "962a8538600e357c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:00.846289Z",
     "start_time": "2024-07-15T16:56:00.841879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_csv_to_matrix(input_csv, format):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    df['row'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "    df['col'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "    \n",
    "    max_row = df['row'].max()\n",
    "    max_col = df['col'].max()\n",
    "\n",
    "    if(format == \"zero\"):\n",
    "        matrix = np.zeros((max_row, max_col))\n",
    "        for index, row in df.iterrows():\n",
    "            matrix[row['row']-1, row['col']-1] = row['Prediction']\n",
    "\n",
    "    else:\n",
    "        # Initialize and populate dictionary to store rows\n",
    "        row_dict = {i: {} for i in range(1, max_row + 1)}\n",
    "        for index, row in df.iterrows():\n",
    "            row_dict[row['row']][row['col']] = row['Prediction']\n",
    "\n",
    "\n",
    "        matrix = np.full((max_row, max_col), np.nan)\n",
    "        for r in range(1, max_row + 1):\n",
    "            for c in range(1, max_col + 1):\n",
    "                if c in row_dict[r]:\n",
    "                    matrix[r-1, c-1] = row_dict[r][c]\n",
    "    \n",
    "    return matrix"
   ],
   "id": "f857a93f273d41da",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:02.062633Z",
     "start_time": "2024-07-15T16:56:02.059004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mean_matrix(matrix):\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r])\n",
    "    return matrix"
   ],
   "id": "b87e0a4159deb6c8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:02.730066Z",
     "start_time": "2024-07-15T16:56:02.726989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_matrix(matrix):\n",
    "    # Normalize the matrix by subtracting the row mean\n",
    "    for r in range(matrix.shape[0]):\n",
    "        row_mean = np.nanmean(matrix[r])\n",
    "        matrix[r] = np.where(np.isnan(matrix[r]), row_mean, matrix[r]) - row_mean\n",
    "    \n",
    "    return matrix"
   ],
   "id": "964fe6b66deca18e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:03.267525Z",
     "start_time": "2024-07-15T16:56:03.265482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scale_matrix(matrix):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_matrix = scaler.fit_transform(matrix)\n",
    "    \n",
    "    return scaled_matrix"
   ],
   "id": "4e29455e692c017a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:03.962123Z",
     "start_time": "2024-07-15T16:56:03.959233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def shrink(S, shrinkage_tau):\n",
    "    S[:] -= shrinkage_tau\n",
    "    return torch.clamp(S, min=0)"
   ],
   "id": "9714d032bff4e28c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T16:56:26.847746Z",
     "start_time": "2024-07-15T16:56:26.844674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_matrix_to_csv(matrix, relevant_values_csv, output_csv):\n",
    "    # Import the relevant values csv and convert to dataframe\n",
    "    relevant_values_df = pd.DataFrame(convert_csv_to_matrix(relevant_values_csv, 'zero'))\n",
    "    \n",
    "    matrix_df = pd.DataFrame(matrix)\n",
    "    \n",
    "    # Create a filtered version of the matrix. The criteria used is: relevant_values_df == 3\n",
    "    filtered_matrix_df = matrix_df.where(relevant_values_df == 3, other=np.nan)\n",
    "    \n",
    "    # Reshape the matrix into one column and reset the index; also removes NaN values\n",
    "    stacked_df = filtered_matrix_df.stack().reset_index()\n",
    "    \n",
    "    # Rename the columns\n",
    "    stacked_df.columns = ['row', 'col', 'val']\n",
    "    \n",
    "    # Create the desired rN_cN format for the final output\n",
    "    stacked_df['row'] = (stacked_df['row'] + 1).astype(str)\n",
    "    stacked_df['col'] = (stacked_df['col'] + 1).astype(str)\n",
    "    stacked_df['r_c'] = 'r' + stacked_df['row'] + '_c' + stacked_df['col']\n",
    "    \n",
    "    result_df = stacked_df[['r_c', 'val']]\n",
    "    \n",
    "    result_df.to_csv(output_csv, index=False, header=['Id', 'Prediction'])"
   ],
   "id": "d328033b27f744b2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T17:17:30.760376Z",
     "start_time": "2024-07-15T17:17:09.687229Z"
    }
   },
   "cell_type": "code",
   "source": "matrix = convert_csv_to_matrix(input_csv, 'zero')",
   "id": "2252b8b6694fd6db",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T17:18:04.812446Z",
     "start_time": "2024-07-15T17:18:04.806952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch_matrix = torch.from_numpy(matrix)\n",
    "# known_values_mask = ~torch.isnan(torch_matrix)\n",
    "known_values_mask = torch_matrix != 0\n",
    "# print(torch.sum(known_values_mask))"
   ],
   "id": "62a0bea58c17f50b",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T17:18:05.208803Z",
     "start_time": "2024-07-15T17:18:05.206005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- matrices for cross validation: Comment to disable\n",
    "\n",
    "testing_values_mask = known_values_mask.clone()\n",
    "#testing_values_mask[:,:990] = False # testing data mask\n",
    "\n",
    "#known_values_mask[:,990:] = False # training data mask\n",
    "\n",
    "# ---- matrices for cross validation: Comment to disable"
   ],
   "id": "64c64a8476a3c252",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T21:27:17.464841Z",
     "start_time": "2024-07-15T21:27:17.451138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows, cols = 10000, 1000\n",
    "rank = 15\n",
    "lam = 0.01\n",
    "num_iterations = 100\n",
    "predictions=[]\n",
    "\n",
    "torch.manual_seed(31415)\n",
    "\n",
    "A = torch_matrix.float()\n",
    "\n",
    "U = torch.randn(rows, rank)\n",
    "V = torch.randn(cols, rank)"
   ],
   "id": "850c513657bc8498",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T21:27:18.103527Z",
     "start_time": "2024-07-15T21:27:18.101010Z"
    }
   },
   "cell_type": "code",
   "source": "U.shape[0]",
   "id": "af95350c490d3b2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T21:27:18.519386Z",
     "start_time": "2024-07-15T21:27:18.516770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_Q(input_matrix):\n",
    "    dim_1 = input_matrix.shape[0]   # Rows or Columns \n",
    "    dim_rank = input_matrix.shape[1]   # Rank\n",
    "    \n",
    "    Q = torch.zeros(dim_1, dim_rank, dim_rank)\n",
    "    for i in range(dim_1):\n",
    "        Q[i] = input_matrix[i].unsqueeze(0).T @ input_matrix[i].unsqueeze(0)\n",
    "        \n",
    "    return Q"
   ],
   "id": "e2a27824c6e24ee",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T21:27:18.970568Z",
     "start_time": "2024-07-15T21:27:18.967827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimize_matrix_ALS(Q, B, optimizable_matrix):\n",
    "    dim_optimizable = optimizable_matrix.shape[0]   # Rows or Columns\n",
    "    dim_fixed = Q.shape[0]\n",
    "    dim_rank = optimizable_matrix.shape[1]   # Rank\n",
    "    \n",
    "    for j in range(dim_optimizable):\n",
    "        sum_r1_mat = 0\n",
    "        for i in range(dim_fixed):\n",
    "            if known_values_mask[i, j]:\n",
    "                sum_r1_mat += Q[i, :, :]\n",
    "        inv = torch.linalg.inv(sum_r1_mat + 2 * lam * torch.eye(dim_rank)).double()\n",
    "        optimizable_matrix[j] = inv @ B[:, j]\n",
    "    \n",
    "    return optimizable_matrix"
   ],
   "id": "e56e596329aaf7b7",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T22:30:00.338526Z",
     "start_time": "2024-07-15T21:27:20.092213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predicted_ratings = A.clone()\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "\n",
    "    Q_U = calculate_Q(U)\n",
    "\n",
    "    B_U = U.T @ A\n",
    "\n",
    "    # V= optimize_matrix_ALS(Q_U, B_U, V)\n",
    "    for col in range(cols):\n",
    "        sum_r1_mat_U = 0\n",
    "        for row in range(rows):\n",
    "            if A[row, col]:\n",
    "                sum_r1_mat_U += Q_U[row, :, :]\n",
    "        inv = torch.linalg.inv(sum_r1_mat_U + 2 * lam * torch.eye(rank))\n",
    "        V[col] = inv @ B_U[:, col]\n",
    "\n",
    "    Q_V = calculate_Q(V)\n",
    "\n",
    "    B_V = V.T @ A.T\n",
    "    \n",
    "    # U = optimize_matrix_ALS(Q_V, B_V, U)\n",
    "    for row in range(rows):\n",
    "        sum_r1_mat_V = 0\n",
    "        for col in range(cols):\n",
    "            if A[row, col]:\n",
    "                sum_r1_mat_V += Q_V[col, :, :]\n",
    "        inv = torch.linalg.inv(sum_r1_mat_V + 2 * lam * torch.eye(rank))\n",
    "        U[row] = inv @ B_V[:, row]\n",
    "\n",
    "    predicted_ratings = U @ V.T\n",
    "    predictions.append(predicted_ratings)\n",
    "    loss = torch.nn.functional.mse_loss(predicted_ratings[testing_values_mask], A[testing_values_mask])\n",
    "    print(f\"Iteration {iteration + 1}/{num_iterations}, Loss: {loss.item()}\")\n",
    "\n",
    "matrix_out = torch.clamp(predicted_ratings, min=1.0, max=5.0)"
   ],
   "id": "85eed9f1ea406e65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100, Loss: 3.659222364425659\n",
      "Iteration 2/100, Loss: 0.838337242603302\n",
      "Iteration 3/100, Loss: 0.7951938509941101\n",
      "Iteration 4/100, Loss: 0.77431720495224\n",
      "Iteration 5/100, Loss: 0.7625187635421753\n",
      "Iteration 6/100, Loss: 0.7551910877227783\n",
      "Iteration 7/100, Loss: 0.7502580285072327\n",
      "Iteration 8/100, Loss: 0.7467105984687805\n",
      "Iteration 9/100, Loss: 0.7440354228019714\n",
      "Iteration 10/100, Loss: 0.7419514060020447\n",
      "Iteration 11/100, Loss: 0.7402875423431396\n",
      "Iteration 12/100, Loss: 0.7389310598373413\n",
      "Iteration 13/100, Loss: 0.7378060221672058\n",
      "Iteration 14/100, Loss: 0.736859917640686\n",
      "Iteration 15/100, Loss: 0.7360562086105347\n",
      "Iteration 16/100, Loss: 0.7353681921958923\n",
      "Iteration 17/100, Loss: 0.7347750067710876\n",
      "Iteration 18/100, Loss: 0.7342600226402283\n",
      "Iteration 19/100, Loss: 0.733809769153595\n",
      "Iteration 20/100, Loss: 0.7334129810333252\n",
      "Iteration 21/100, Loss: 0.7330607771873474\n",
      "Iteration 22/100, Loss: 0.7327459454536438\n",
      "Iteration 23/100, Loss: 0.7324627637863159\n",
      "Iteration 24/100, Loss: 0.7322067022323608\n",
      "Iteration 25/100, Loss: 0.7319742441177368\n",
      "Iteration 26/100, Loss: 0.7317622900009155\n",
      "Iteration 27/100, Loss: 0.7315685153007507\n",
      "Iteration 28/100, Loss: 0.7313905358314514\n",
      "Iteration 29/100, Loss: 0.7312268018722534\n",
      "Iteration 30/100, Loss: 0.7310753464698792\n",
      "Iteration 31/100, Loss: 0.7309350967407227\n",
      "Iteration 32/100, Loss: 0.7308045029640198\n",
      "Iteration 33/100, Loss: 0.7306826710700989\n",
      "Iteration 34/100, Loss: 0.7305687665939331\n",
      "Iteration 35/100, Loss: 0.7304616570472717\n",
      "Iteration 36/100, Loss: 0.7303608655929565\n",
      "Iteration 37/100, Loss: 0.7302656769752502\n",
      "Iteration 38/100, Loss: 0.7301753759384155\n",
      "Iteration 39/100, Loss: 0.730089545249939\n",
      "Iteration 40/100, Loss: 0.7300078868865967\n",
      "Iteration 41/100, Loss: 0.7299299240112305\n",
      "Iteration 42/100, Loss: 0.7298552989959717\n",
      "Iteration 43/100, Loss: 0.7297836542129517\n",
      "Iteration 44/100, Loss: 0.7297147512435913\n",
      "Iteration 45/100, Loss: 0.7296484708786011\n",
      "Iteration 46/100, Loss: 0.7295845746994019\n",
      "Iteration 47/100, Loss: 0.7295230031013489\n",
      "Iteration 48/100, Loss: 0.7294633984565735\n",
      "Iteration 49/100, Loss: 0.7294057607650757\n",
      "Iteration 50/100, Loss: 0.7293500304222107\n",
      "Iteration 51/100, Loss: 0.7292961478233337\n",
      "Iteration 52/100, Loss: 0.729243814945221\n",
      "Iteration 53/100, Loss: 0.7291929721832275\n",
      "Iteration 54/100, Loss: 0.7291436791419983\n",
      "Iteration 55/100, Loss: 0.7290957570075989\n",
      "Iteration 56/100, Loss: 0.7290493249893188\n",
      "Iteration 57/100, Loss: 0.72900390625\n",
      "Iteration 58/100, Loss: 0.7289599180221558\n",
      "Iteration 59/100, Loss: 0.7289170622825623\n",
      "Iteration 60/100, Loss: 0.7288752794265747\n",
      "Iteration 61/100, Loss: 0.7288347482681274\n",
      "Iteration 62/100, Loss: 0.7287952303886414\n",
      "Iteration 63/100, Loss: 0.7287567853927612\n",
      "Iteration 64/100, Loss: 0.728719174861908\n",
      "Iteration 65/100, Loss: 0.7286826372146606\n",
      "Iteration 66/100, Loss: 0.728646993637085\n",
      "Iteration 67/100, Loss: 0.7286122441291809\n",
      "Iteration 68/100, Loss: 0.7285781502723694\n",
      "Iteration 69/100, Loss: 0.7285448908805847\n",
      "Iteration 70/100, Loss: 0.7285122275352478\n",
      "Iteration 71/100, Loss: 0.728480339050293\n",
      "Iteration 72/100, Loss: 0.7284488081932068\n",
      "Iteration 73/100, Loss: 0.7284180521965027\n",
      "Iteration 74/100, Loss: 0.728387713432312\n",
      "Iteration 75/100, Loss: 0.7283579111099243\n",
      "Iteration 76/100, Loss: 0.72832852602005\n",
      "Iteration 77/100, Loss: 0.7282998561859131\n",
      "Iteration 78/100, Loss: 0.7282717227935791\n",
      "Iteration 79/100, Loss: 0.7282443046569824\n",
      "Iteration 80/100, Loss: 0.7282174825668335\n",
      "Iteration 81/100, Loss: 0.7281913161277771\n",
      "Iteration 82/100, Loss: 0.7281657457351685\n",
      "Iteration 83/100, Loss: 0.7281408309936523\n",
      "Iteration 84/100, Loss: 0.7281164526939392\n",
      "Iteration 85/100, Loss: 0.7280926704406738\n",
      "Iteration 86/100, Loss: 0.7280694246292114\n",
      "Iteration 87/100, Loss: 0.7280466556549072\n",
      "Iteration 88/100, Loss: 0.728024423122406\n",
      "Iteration 89/100, Loss: 0.7280027270317078\n",
      "Iteration 90/100, Loss: 0.727981448173523\n",
      "Iteration 91/100, Loss: 0.7279606461524963\n",
      "Iteration 92/100, Loss: 0.7279403209686279\n",
      "Iteration 93/100, Loss: 0.727920413017273\n",
      "Iteration 94/100, Loss: 0.7279008030891418\n",
      "Iteration 95/100, Loss: 0.7278816103935242\n",
      "Iteration 96/100, Loss: 0.7278628945350647\n",
      "Iteration 97/100, Loss: 0.7278443574905396\n",
      "Iteration 98/100, Loss: 0.7278260588645935\n",
      "Iteration 99/100, Loss: 0.7278080582618713\n",
      "Iteration 100/100, Loss: 0.7277904152870178\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 56,
   "source": [
    "# Save the matrix to the output CSV\n",
    "# You can also choose an intermediary prediction from a certain iteration. They are saved in the list predictions[iteration - 1]\n",
    "save_matrix_to_csv(matrix_out, relevant_values_csv, output_csv)"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
